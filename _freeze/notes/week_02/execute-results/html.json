{
  "hash": "d0b9fb2d06b7c1f50ed58e28249c30ea",
  "result": {
    "markdown": "---\ntitle: \"Exploring Data with `tidyverse`\"\noutput:\n  html_document:\n    toc: true\n---\n\n\n\n\n# 1. Data Description\n\nWe will use two data sets for illustration.\n\n## 1.1 Chicago Redlining\n\nInsurance redlining refers to the practice of refusing to issue insurance to certain\ntypes of people or within some geographic area. The name comes from the act of\ndrawing a red line around an area on a map. Now few would quibble with an insurance\ncompany refusing to sell auto insurance to a frequent drunk driver, but other\nforms of discrimination would be unacceptable.\n\nIn the late 1970s, the US Commission on Civil Rights examined charges by several\nChicago community organizations that insurance companies were redlining their\nneighborhoods. Because comprehensive information about individuals being refused\nhomeowners insurance was not available, the number of FAIR plan policies written\nand renewed in Chicago by ZIP code for the months of December 1977 through May\n1978 was recorded. The FAIR plan was offered by the city of Chicago as a default\npolicy to homeowners who had been rejected by the voluntary market. Information\non other variables that might affect insurance writing such as fire and theft rates was\nalso collected at the ZIP code level. The variables are:\n\n* `involact` new FAIR plan policies and renewals per 100 housing units,\n* `fire` fires per 100 housing units,\n* `theft` thefts per 1000 population,\n* `race` racial composition in percentage of minority,\n* `age` (of housing) percentage of housing units built before 1939,\n* `income` median family income in thousands of dollars,\n* `side` north or south side of Chicago.\n\nThe variable `involact` acts as a measure of insurance availability in the voluntary market, since most FAIR plan policyholders secure such coverage only after they have been rejected by the voluntary market. Insurance companies claim to reject insurances based on their past losses (captured in variables `theft` and `fire`). The U.S. Commission on Civil Rights in 1979 was interested in how much `income`, `age` of housing, and in particular `race` affect insurance availability.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(faraway)\ndata(chredlin, package=\"faraway\") # attaches the data from the faraway package\nhead(chredlin)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      race fire theft  age involact income side\n60626 10.0  6.2    29 60.4      0.0 11.744    n\n60640 22.2  9.5    44 76.5      0.1  9.323    n\n60613 19.6 10.5    36 73.5      1.2  9.948    n\n60657 17.3  7.7    37 66.9      0.5 10.656    n\n60614 24.5  8.6    53 81.4      0.7  9.730    n\n60610 54.0 34.1    68 52.6      0.3  8.231    n\n```\n:::\n:::\n\n\n## 1.2 Flights\n\nThe following data set contains about 1/4 million flights that departed from New York City in 2014.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table)\nflights <- fread(\"https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv\")\n# 1/4 million rows, so subsample\n```\n:::\n\n\nThe variables are self-explanatory in this case\n\nSince the data has so many rows, let's sub-sample it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# flights <- flights[sample(1:dim(flights)[1], 5000),] # base R version of sub-sampling\nlibrary(tidyverse)\nflights <- flights %>%\n  slice_sample(n=5000)                               # tidyverse version of sub-sampling\nhead(flights)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   year month day dep_delay arr_delay carrier origin dest air_time distance\n1: 2014     5  22        82        60      UA    EWR  SFO      328     2565\n2: 2014     8  23        -4       -30      UA    EWR  LAX      308     2454\n3: 2014     9  22         6         6      DL    LGA  MSY      160     1183\n4: 2014     7  25        38        14      AA    JFK  SFO      330     2586\n5: 2014     5  10        -5        11      WN    EWR  STL      135      872\n6: 2014     2   7        -4        21      UA    EWR  SFO      381     2565\n   hour\n1:   16\n2:    8\n3:   15\n4:   11\n5:    6\n6:    6\n```\n:::\n:::\n\n\n# 2. Data Manipulation\n\nThe basic functions which will allow us to do most of the data manipulation tasks are\n\n* `filter` picks observations by chosen values\n  - `select` picks variables (by their names), hence is a poor \"transpose\" of `filter`\n* `mutate` creates new variables as functions of existing ones\n* `arrange` orders the observations\n* `group_by` allows all of the above to work locally\n  - `summarize` collapses values down to a single summary -- only useful together with `group_by`\n\nFirst, let us drop the non-numerical variables. We can either select all but what we want to drop or, more conveniently, use the minus-notation to specify directly what we want to drop.\n\n::: {.cell}\n\n```{.r .cell-code}\nflights <- select(flights, -carrier, -origin, -dest)\nhead(flights)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   year month day dep_delay arr_delay air_time distance hour\n1: 2014     5  22        82        60      328     2565   16\n2: 2014     8  23        -4       -30      308     2454    8\n3: 2014     9  22         6         6      160     1183   15\n4: 2014     7  25        38        14      330     2586   11\n5: 2014     5  10        -5        11      135      872    6\n6: 2014     2   7        -4        21      381     2565    6\n```\n:::\n:::\n\n\n\nAs an example, let us filter flights that departed on the April Fool's day:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfools <- filter(flights, month == 4, day == 1) # all flights on April 1st\nsummarize(fools, n()) # in our sub-sample, we have 17 flights on April 1st\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  n()\n1  17\n```\n:::\n:::\n\n\nWhen working with tidyverse, it is customary to use the \"pipe\" operator `%>%`. Basically, `f(x,y)` is equivalent to `x %>% f(y)`. This is useful when chaining operations (composing functions), e.g.,\n```\ng(f(x,y),z)  # is equivalent to\nx %>% f(y) %>% g(z)\n```\nWhile mathematically we are composing functions, for data manipulation it is often useful to think about chaining operations, i.e., using the pipe `%>%`.\n\nFor example, the two lines of code above can be tweaked to not store the `fools` variable by either composing functions or chaining operations:\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarize(filter(flights, month == 4, day == 1), n()) # or\nflights %>% filter(month ==4, day == 1) %>% summarize(n())\n```\n:::\n\n\nWhat if we want to know the number of flights on any given day?\n\n::: {.cell}\n\n```{.r .cell-code}\nflights %>% \n  group_by(month, day) %>% \n  summarize(n()) %>% \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 Ã— 3\n# Groups:   month [1]\n  month   day `n()`\n  <int> <int> <int>\n1     1     1    13\n2     1     2    14\n3     1     3     9\n4     1     4    14\n5     1     5    13\n6     1     6    12\n```\n:::\n:::\n\n\nThe original data set was arranged by `month`, `day` and `hour`, but we have lost this ordering by sub-sampling.\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(flights)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   year month day dep_delay arr_delay air_time distance hour\n1: 2014     5  22        82        60      328     2565   16\n2: 2014     8  23        -4       -30      308     2454    8\n3: 2014     9  22         6         6      160     1183   15\n4: 2014     7  25        38        14      330     2586   11\n5: 2014     5  10        -5        11      135      872    6\n6: 2014     2   7        -4        21      381     2565    6\n```\n:::\n:::\n\nSo let's fix this by `arrange()`.\n\n::: {.cell}\n\n```{.r .cell-code}\nflights <- flights %>% \n  arrange(month, day, hour)\nhead(flights)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   year month day dep_delay arr_delay air_time distance hour\n1: 2014     1   1        61        62      157     1069   10\n2: 2014     1   1        10         4      155     1023   11\n3: 2014     1   1        24        34      165     1069   13\n4: 2014     1   1        39        21      355     2565   13\n5: 2014     1   1        -2       -23      160     1096   15\n6: 2014     1   1         3       -10      349     2475   16\n```\n:::\n:::\n\n\nLet's read and sub-sample the data again\n\n::: {.cell}\n\n```{.r .cell-code}\nflights <- fread(\"https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv\")\nflights <- flights %>%\n  slice_sample(n=5000)\nstr(flights)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nClasses 'data.table' and 'data.frame':\t5000 obs. of  11 variables:\n $ year     : int  2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 ...\n $ month    : int  4 8 8 8 9 7 4 4 3 7 ...\n $ day      : int  25 29 17 11 2 29 20 17 10 11 ...\n $ dep_delay: int  17 -2 27 15 4 -7 -8 -9 -5 0 ...\n $ arr_delay: int  -2 -21 29 1 -20 -7 -53 29 -13 -8 ...\n $ carrier  : chr  \"US\" \"DL\" \"EV\" \"B6\" ...\n $ origin   : chr  \"LGA\" \"EWR\" \"EWR\" \"JFK\" ...\n $ dest     : chr  \"BOS\" \"ATL\" \"BNA\" \"BQN\" ...\n $ air_time : int  32 96 106 187 229 158 329 68 122 69 ...\n $ distance : int  184 746 748 1576 1620 1089 2586 405 733 483 ...\n $ hour     : int  16 10 18 0 10 6 8 16 14 20 ...\n - attr(*, \".internal.selfref\")=<externalptr> \n```\n:::\n:::\n\nWe may notice that `carrier`, `origin` and `dest` are characters, but they should actually be factors.\nWe can use `mutate()` to rectify that:\n\n::: {.cell}\n\n```{.r .cell-code}\nflights <- flights %>%\n  mutate(carrier = as.factor(carrier),\n          origin = as.factor(origin),\n            dest = as.factor(dest))\nstr(flights) # to see the overall structure of the object flights\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nClasses 'data.table' and 'data.frame':\t5000 obs. of  11 variables:\n $ year     : int  2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 ...\n $ month    : int  4 8 8 8 9 7 4 4 3 7 ...\n $ day      : int  25 29 17 11 2 29 20 17 10 11 ...\n $ dep_delay: int  17 -2 27 15 4 -7 -8 -9 -5 0 ...\n $ arr_delay: int  -2 -21 29 1 -20 -7 -53 29 -13 -8 ...\n $ carrier  : Factor w/ 14 levels \"AA\",\"AS\",\"B6\",..: 12 4 5 3 14 1 3 9 1 9 ...\n $ origin   : Factor w/ 3 levels \"EWR\",\"JFK\",\"LGA\": 3 1 1 2 3 2 2 3 3 2 ...\n $ dest     : Factor w/ 98 levels \"ABQ\",\"ACK\",\"ALB\",..: 12 5 11 13 29 56 85 77 65 25 ...\n $ air_time : int  32 96 106 187 229 158 329 68 122 69 ...\n $ distance : int  184 746 748 1576 1620 1089 2586 405 733 483 ...\n $ hour     : int  16 10 18 0 10 6 8 16 14 20 ...\n - attr(*, \".internal.selfref\")=<externalptr> \n```\n:::\n:::\n\n\nThe verb `mutate()` can also be used to create new variables from existing variables. For example, we might want to calculate what would the air-time be if there were no delays, or we might want to create a single departure time column using day, month and hour.\n\n::: {.cell}\n\n```{.r .cell-code}\nflights <- flights %>%\n  mutate(no_delay_air_time = air_time + dep_delay - arr_delay,\n         HHDDMMYYYY = 10^8*hour + 10^6*day + 10^4*month + year)\n```\n:::\n\nNote: the way we created the `HHDDMMYYYY` is only for illustration purposes, there are better ways to handle time variables!\n\n# 3. Basic Charts\n\n## 3.1 Histograms\n\nBasic bar plot showing number of flights for different carriers:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = flights) + \n  geom_bar(mapping = aes(x = carrier))\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nWe can split every bar by departure airport (i.e., variable `origin`) by adding the `fill` argument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = flights) + \n  geom_bar(mapping = aes(x = carrier, fill = origin))\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nIf we wanted one histogram for each NY airport instead, we could use `facet_wrap`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = flights) + \n  geom_bar(mapping = aes(x = carrier)) +\n  facet_wrap(~ origin)\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nWhat if we wanted to add numbers denoting the bin sizes?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = flights) + \n  geom_bar(mapping = aes(x = carrier)) +\n  stat_count(mapping = aes(x = carrier, label=..count.., y=..count.. + 40), geom=\"text\", size=4, color=\"blue\")\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nTo show labels for split bars above, one just adds `group=origin` in the `stat_count`'s `aes`, but it is impossible to vertically align the text properly. We bypass it by creating a new variable `veralign`, which controls the vertical alignment.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_flights <- flights %>%\n  group_by(origin, carrier) %>%\n  summarise(count = n()) %>% # now we have a table with the hist cell counts\n  ungroup() %>%\n  group_by(carrier) %>%\n  arrange(desc(origin)) %>% # needed because histogram ordered alphabetically from the top\n  mutate(veralign = cumsum(count) - count/2) %>% # here we calculate the vertical alignment and append it to the data set\n  ungroup() # drop the grouping\n\nggplot() + \n  geom_bar(data = flights, mapping = aes(x = carrier, fill = origin)) +\n  geom_text(data=n_flights, mapping = aes(x = carrier, label=count, y=veralign), size=4)\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nAs long as we are plotting frequencies of occurrence, there is little difference between bar plots and histograms. If the variable on the x-axis is categorical, we speak of bar plots, while if the variable is numerical and some binning has to be done, we speak of histograms. For example:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(viridis)\nflights %>%\n  ggplot( aes(x=arr_delay_log, fill=origin)) +\n    geom_histogram( color=\"#e9ecef\", alpha=0.6) +\n    scale_fill_viridis(discrete = TRUE) +\n    labs(fill=\"\")\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nBut we may also scale the y-axis to show probabilities (total area equal to one), instead of frequencies (total area equal to the number of observations). In such a case, histogram can be considered as an estimator of density function (more on that later in the semester). Hence histograms are often overlaid with other density estimators. We will see that later.\n\n\n## 3.2 Scatterplots\n\nHere we take a look again at the insurance redlining data, where we are interested in the effect of `race` on the response variable. Let's start with the marginal relationship of the response on `race`, which is what we are mostly interested in. We can distinguish \n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = chredlin,\n       mapping = aes(x = race, y = involact, color = side, shape = side)) +\n  geom_point() + scale_color_manual(values = c(\"blue\",\"red\")) +\n  scale_shape_manual(values = c(1,2))\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = chredlin, mapping = aes(x = race, y = involact,\n                                      shape = side, color = side)) +\n  geom_point() + # adds a layer to the empty plot above\n  stat_smooth(method=lm) +# adds a regression line too \n  scale_color_manual(values = c(\"blue\",\"red\")) +\n  scale_shape_manual(values = c(1,2))\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\nThere is probably no difference between north and south w.r.t. the relationship between the response and `race`, but it might be a different story for `fire`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = chredlin, mapping = aes(x = fire, y = involact, shape = side, color = side)) +\n  geom_point() + # adds a layer to the empty plot above\n  stat_smooth(method=lm)+ # adds a regression line too\n  scale_color_manual(values = c(\"blue\",\"red\")) +\n  scale_shape_manual(values = c(1,2))\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\nWhat if I want only a single regression line but ability to distinguish between points at the same time? I could either use different mappings for every layer\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = chredlin) +\n  geom_point(mapping = aes(x = fire, y = involact, shape = side, color = side)) +\n  stat_smooth(method=lm, mapping=aes(x = fire, y = involact), color = \"purple\")+\n  scale_color_manual(values = c(\"blue\",\"red\")) +\n  scale_shape_manual(values = c(1,2))\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\nor, equivalently, use one global mapping in ggplot (the most general one) and then specify it a bit more for some layers\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = chredlin, mapping=aes(x = fire, y = involact)) +\n  geom_point(mapping = aes(shape = side, color = side)) +\n  stat_smooth(method=lm, color = \"purple\")\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\nIf we want to split into multiple plots, use the `facet_wrap` function\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = chredlin, mapping = aes(x = fire, y = involact, shape = side, color = side)) +\n  geom_point() +\n  stat_smooth(method=lm, color = \"purple\") +\n  facet_wrap(~ side) # split by a value of a factor\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\nFor faceting by two factor variables, we can use `facet_grid` instead, such as if we wanted to create scatterplots for our `flights` data, split by `carrier` and `origin` (we filter only some carriers so we don't have too many plots).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights %>%\n  filter(carrier %in% c(\"AA\", \"UA\", \"DL\", \"US\")) %>%\n  ggplot(mapping = aes(x = dep_delay, y = arr_delay)) +\n  geom_point() +\n  stat_smooth(method=lm) +\n  facet_grid(origin ~ carrier)\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\nExercise: create histograms of `dep_delay` for all three `origins` and seven consecutive days in the `flights` data set.\n\nBack to the `chredlin` data set, we take a closer look at some observations in the scatterplot of `involact` and `fire`, that might be outliers or leverage points:\n\n\n::: {.cell}\n\n```{.r .cell-code}\noutliers <- c(3,6,35)\nleverage_pts <- c(7,24)\noutliers <- chredlin[outliers,]\nleverage_pts <- chredlin[leverage_pts,]\n```\n:::\n\n\nLet's now make some scatterplots with the outliers and leverage points highlighted by overploting.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  geom_point(data = chredlin, mapping = aes(x = fire, y = involact)) +\n  geom_point(data = outliers, mapping = aes(x = fire, y = involact), col = \"blue\", pch = 17, size=3) +\n  geom_point(data = leverage_pts, mapping = aes(x = fire, y = involact), col = \"red\", pch = 18, size=3)\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\nAlternatively, we could incorporate the information about which points are outliers and which are leverage points into the data set as a new variable and use it for plotting. The code is quite ugly (notice how we start with booleans, then turn them into numericals, and then re-type them into factors), but it does the job.\n\n\n::: {.cell}\n\n```{.r .cell-code}\noutliers <- I(1:nrow(chredlin) %in% c(3,6,35))\nleverage_pts <- I(1:nrow(chredlin) %in% c(7,24))\nchredlin <- chredlin %>%\n  mutate(out_lev =  as.factor(outliers + 2*leverage_pts))\nlevels(chredlin$out_lev) <- c(\"normal obs\", \"outlier\", \"leverage point\")\n\nggplot(data = chredlin) +\n  geom_point(mapping = aes(x = fire, y = involact, shape = out_lev, color = out_lev, size = out_lev)) +\n  scale_size_manual(values = c(2,4,4))\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\nAnother alternative would be to use `fortify()` to add residuals and Cook's distances from a linear model fit directly to the data set. Then we could use `mutate()` more naturally to decide which observations are outliers and leverage points.\n\n## 3.3 Boxplots\n\nSimilarly to histograms, boxplots can give us some idea about distributions. Unlike histograms, boxplots do not really capture an underlying density shape, but only visually give several summary statistics and points in the tails.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights %>%\n  filter(carrier %in% c(\"AA\", \"B6\", \"DL\", \"EV\")) %>%\n  ggplot( aes(x=carrier, y= arr_delay_log, fill=carrier)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE) +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Boxplot by factor\") +\n    xlab(\"Carrier\")\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\nUsing the `fill` argument here creates a grouped boxplot, where grouping is given by the `fill` variable. To reduce the size of the plot, we filter only four carriers.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights %>%\n  filter(carrier %in% c(\"AA\", \"B6\", \"DL\", \"EV\")) %>%\n  ggplot( aes(x=carrier, y= arr_delay_log, fill=origin)) +\n    geom_boxplot() +\n    scale_fill_viridis(discrete = TRUE) +\n    theme(\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"Boxplot by two factors\") +\n    xlab(\"Carrier\")\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n## 3.4 Multiple Plots\n\nThere are numerous ways how to display multiple plots. The default is to set `par(mfrow = c(n_rows, n_cols))` before plotting, an alternative is the `lattice` package, but these do not work with `ggplot`. With `ggplot`, one can utilize `ggarrange()` from the `ggpubr` package. However, these will require you to do a lot of copy-pasting since you still need to create plots individually, but sometimes we want to create numerous plots similar in nature. To this point, the `ggplot2`'s `facet_wrap` function allows you to split into numerous plots by a value of a factor.\n\nBut what if we wish to create one plot for every variable? This is doable with `facet_wrap` provided we have:\n\n* all the values (in our data frame) given as a single variable\n* another variable linking the original variables to the values.\n\nThis is exactly what we get by using `pivot_longer()` below. The argument `everything()` specifies we want to keep all the variables, otherwise we could use the variable names like with `select()` (just here, multiple variables have to be wrapped in `c()` due to the function's syntax) to keep only some or discard some variables. `pivot_longer()` will give us a long-format data frame with two columns: `value` and `name`. Then we plot `value` and wrap the facets based on `name`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(chredlin, package=\"faraway\")\nchredlin %>% mutate(side = as.numeric(side)) %>% \n  pivot_longer(everything()) %>%\n  ggplot(aes(value)) + facet_wrap(~ name, scales = \"free\") + geom_histogram()\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\nThe complement of `pivot_longer()` is `pivot_wider()`. We may want to use it, e.g., after `group_by()` and `summarize()`, which naturally lead to a long table. For example, assume we want to produce a heatmap of the average departure delay of flights on different days (x-axis) and months (y-axis), in order to see average departure delay in a calendar-like fashion. While this is not terribly useful, it is done below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_dat <- flights %>% \n  group_by(month, day) %>%\n  summarize(count = mean(dep_delay)) %>%\n  pivot_wider(names_from = day, values_from = count) %>%\n  ungroup() %>% select(-month)\n\nlibrary(lattice)\nlibrary(viridisLite)\ncoul <- plasma(100)\nlevelplot(t(as.matrix(new_dat)), col.regions = rev(coul), xlab=\"Day\", ylab=\"Month\", main=\"Departure delay\")\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\nWhile we could create a heatmap using `ggplot2`'s `geom_tile()`, I personally find `levelplot()` of the `lattice` package more useful for quick plotting. One can do great heatmaps with `ggplot2` and `geom_tile()`, but it requires some work to set up the color schemes and to magnify the colorkey.\n\nWhile the previous heatmap is not so useful, we will later see that heatmaps are quite handy e.g. when probing performance of a certain method based on two parameters.\n\n<!-- ## 3.5 Line Plots -->\n\n<!-- There is nothing interesting about line plots, they are probably the first thing that comes to anyone's mind under the word \"plot\". -->\n<!-- They are mostly useful when there is a linearly ordered variable, typically time, and we are interested in evolution of some of the other variables with respect to the linearly ordered variable. -->\n\n<!-- For example, below we load the data containing the cumulative number of Covid-19 cases for different countries. However, the data are in a weird format, so we get to practice some data wrangling as well. -->\n\n<!-- ```{r} -->\n<!-- covid <- read.csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\") -->\n<!-- str(covid, list.len=8) -->\n<!-- ``` -->\n\n<!-- The data frame has the following structure -->\n\n<!-- * time series for a given country is given as an observation with the name of the country as the variable `Country.Region`, -->\n<!-- * some country names are unique in the variable `Country.Region` while others appear with different multiplicities, distinguished by another `chr` variable `Province.State`, and -->\n<!-- * time is given in variable names and in a strange format, e.g. `X1.22.20` is January 22, 2020. -->\n\n<!-- The first point is generally good, the second point so-so (we will not deal with it and only plot data for 4 countries), and the last one is particularly ugly. To deal with the last one, we basically need to transform the strings like `X1.22.20` into a recognizable format like `2022-01-22`. In general, this can be done via `as.Date()`. -->\n\n<!-- But here, the minimal thing we have to do manually is to get rid of the `X` at the beginning of every string. Instead of figuring out whether the rest can be done implicitly by `as.Date()`, let us write a function below to transform the strings into a recognizable format ourselves. (We still need to use `as.Date()` though to change the object clas from `chr` to `Date`, which can be used for ploting). -->\n\n<!-- ```{r} -->\n<!-- formatDate <- function(dates){ -->\n<!--   res <- c() # input is a vector of chars like `X1.22.20`, the output will be a vector as well -->\n<!--   for(i in 1:length(dates)){ -->\n<!--     splited <- strsplit(dates[i], \"[.]\") # split the string by the dots -->\n<!--     splited <- splited[[1]] # get rid of an empty dimension -->\n<!--     splited[1] <- substr(splited[1],2,nchar(splited)) # drop `X` from the beginning -->\n<!--     splited[3] <- paste(\"20\",splited[3],sep=\"\") # add 20.. to the year values -->\n<!--     res[i] <- paste(splited[3],splited[1],splited[2],sep=\"-\") # combine year-month-day -->\n<!--   } -->\n<!--   return(as.Date(res)) -->\n<!-- } -->\n\n<!-- covid %>%  -->\n<!--   filter(Country.Region %in% c(\"Czechia\",\"Germany\",\"Italy\",\"Switzerland\")) %>% -->\n<!--   pivot_longer(c(-Country.Region,-Province.State,-Lat,-Long)) %>% -->\n<!--   mutate(date=formatDate(name)) %>% -->\n<!--   ggplot(aes(x=date, y=value, colour=Country.Region)) + -->\n<!--     geom_line() + -->\n<!--     ggtitle(\"Cumulative no. of covid cases.\") -->\n<!-- ``` -->\n\n## 3.5 Marginal Scatterplots with Regression Lines and Outliers\n\nIf we fit a linear model to the response variable `involact` with all available variables (except `side`) as covariates, we notice that there are some outliers and leverage points (looking at the Cook's distance). Wouldn't it be nice to add these into the marginal scatterplots directly to see which scatter points belong to the outliers?\n\nFirstly, If we wish to have scatterplots with the response variable `involact` on the y-axes, we naturally need one more column with `involact` values in the long format. This is actually done automatically by dropping `involact` from pivoting.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchredlin %>% mutate(side = as.numeric(side), income=log(income)) %>% \n  pivot_longer(-involact) %>%\n  ggplot(aes(y = involact, x = value)) + facet_wrap(~ name, scales = \"free\") +\n  geom_point() + stat_smooth(method=lm)\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\nSecondly, let's denote the outliers. We will use the second extra-variable approach (as opposed to the over-plotting approach). We create an additional variable which tells us, which of the observations are outliers.\n\n\n::: {.cell}\n\n```{.r .cell-code}\noutliers <- I(1:nrow(chredlin) %in% c(3,6,35))\nleverage_pts <- I(1:nrow(chredlin) %in% c(7,24))\nchredlin <- chredlin %>%\n  mutate(out_lev =  as.factor(outliers + 2*leverage_pts))\nlevels(chredlin$out_lev) <- c(\"normal obs\", \"outlier\", \"leverage point\")\n\nchredlin %>% mutate(side = as.numeric(side), income=log(income)) %>% \n  pivot_longer(cols=c(-involact, -out_lev)) %>%\n  ggplot() + facet_wrap(~ name, scales = \"free\") +\n  geom_point(mapping = aes(y = involact, x = value, color = out_lev)) +\n  stat_smooth(mapping = aes(y = involact, x = value), method=lm)\n```\n\n::: {.cell-output-display}\n![](week_02_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\n# References\n\nWickham & Grolemund (2016) [R for data science](https://r4ds.had.co.nz/)\n\nFaraway (2016) Linear Models with R (2nd Edition)\n",
    "supporting": [
      "week_02_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}